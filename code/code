import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

def generate_matrix_p() -> np.ndarray:
    matrix_p = np.random.rand(1576, 1576)
    return matrix_p


def mask_colum(matrix_input: np.ndarray) -> list:
    matrix_sum = matrix_input.sum(axis=1)
    smallest_p_indics = np.argsort(matrix_sum)[:315]
    return smallest_p_indics.tolist()


def mask(mask_matrix: np.ndarray, mask_list: list) -> np.ndarray:
    mask_matrix[:, mask_list] = 0
    return mask_matrix




def extract_subtree(adj: torch.Tensor,
                    vals: torch.Tensor,
                    node_idx: int):
    """
    从大小为 [N×N] 的 adj 和 vals 中，
    提取以 node_idx 为中心（包含自身）的子图。
    返回：
      sub_adj: [M×M] 二值或权重邻接矩阵（包含自环）
      sub_val: [M×M] 对应的值矩阵
      root_pos: 子图中中心节点的索引（总是 0）
    """
    # 找到所有邻居（非零条目）并包含中心节点自身
    neigh = (adj[node_idx] != 0).nonzero(as_tuple=False).squeeze(1)
    idx = torch.cat([torch.tensor([node_idx], device=adj.device), neigh]).unique()
    # 按 idx 顺序裁剪子矩阵
    sub_adj = adj[idx][:, idx]
    sub_val = vals[idx][:, idx]
    # 加自环
    M = sub_adj.size(0)
    sub_adj = sub_adj.clone()
    sub_adj.fill_diagonal_(1)
    return sub_adj, sub_val, 0  # 中心节点映射到子图中位置 0

class Subgraph_GNN(nn.Module):
    def __init__(self, out_dim: int):
        super().__init__()
        self.lin = nn.Linear(1, out_dim, bias=False)

    def forward(self, sub_adj: torch.Tensor, sub_val: torch.Tensor):
        # 构造归一化加权邻接 A_norm
        A = sub_adj.float() * sub_val
        deg = A.sum(dim=1)
        inv_sqrt = deg.pow(-0.5)
        inv_sqrt[torch.isinf(inv_sqrt)] = 0
        A_norm = inv_sqrt.unsqueeze(1) * A * inv_sqrt.unsqueeze(0)

        # 初始特征：全 1
        h0 = torch.ones(sub_adj.size(0), 1, device=sub_adj.device)
        # 一层 GCN：h = A_norm @ W h0
        return A_norm @ self.lin(h0)

def compute_subtree_embeddings(adj: torch.Tensor,
                               vals: torch.Tensor,
                               model: Subgraph_GNN,
                               pooling: str = 'mean'):
    """
    对所有节点依次提取子图，用 model 计算节点特征，
    并对每个子图做池化，得到 [N×out_dim] 的子图向量。
    """
    N = adj.size(0)
    embeds = []
    for i in range(N):
        sub_adj, sub_val,_ = extract_subtree(adj, vals,i)
        h = model(sub_adj, sub_val)          # [M×out_dim]
        if pooling == 'mean':
            g = h.mean(dim=0)
        elif pooling == 'sum':
            g = h.sum(dim=0)
        else:
            g, _ = h.max(dim=0)
        embeds.append(g)
    return torch.stack(embeds, dim=0)        # [N×out_dim]

class AugmentedAdjacency(nn.Module):
    """
    Compute the augmented adjacency matrix A_aug where:
      A_aug[i, j] = exp(ReLU(m^T |x_i P - x_j P|)) /
                    sum_n exp(ReLU(m^T |x_i P - x_n P|))

    Args:
        P: Pretrained projection matrix (torch.Tensor, shape [F, D])
        m: Learnable weight vector (torch.Tensor, shape [D])
    """
    def __init__(self, P: torch.Tensor, m: torch.Tensor):
        super().__init__()
        # Register P and m as parameters so they will be updated during training
        self.P = nn.Parameter(P)
        self.m = nn.Parameter(m)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: Node features of shape [N, F]
        Returns:
            A_aug: Tensor of shape [N, N]
        """
        # Project node features into D-dimensional space
        X_proj = x @ self.P           # [N, D]

        # Compute pairwise absolute differences: [N, N, D]
        diff = torch.abs(X_proj.unsqueeze(1) - X_proj.unsqueeze(0))

        # Linear score for each pair: [N, N]
        scores = diff @ self.m

        # ReLU then exponentiate
        relu_scores = F.relu(scores)
        exp_scores = torch.exp(relu_scores)

        # Row-normalize to get probabilities
        A_aug = exp_scores / exp_scores.sum(dim=1, keepdim=True)

        return A_aug

def graph_augmentation_loss(A_aug: torch.Tensor, P: torch.Tensor) -> torch.Tensor:
    """
    Compute the augmentation loss:
        L_ag_graph = sum_{i,j} A_aug[i,j] * || (A_aug[i] @ P) - (A_aug[j] @ P) ||^2
                     + ||A_aug||_F^2

    Args:
        A_aug: [N, N] augmented adjacency matrix (row-stochastic or learned weights)
        P:     [N, D] projection matrix (learnable)

    Returns:
        loss:  scalar tensor
    """
    # Compute Z = A_aug @ P, shape [N, D]
    Z = A_aug @ P

    # Compute pairwise differences: [N, N, D]
    diff = Z.unsqueeze(1) - Z.unsqueeze(0)

    # Squared L2 norm of differences: [N, N]
    sq_norm = (diff ** 2).sum(dim=-1)

    # Weighted sum by adjacency entries
    loss_term = (A_aug * sq_norm).sum()

    # Frobenius norm squared of A_aug
    frob_term = torch.norm(A_aug, p='fro') ** 2

    return loss_term + frob_term

# Example usage:
# A_aug = torch.rand(N, N, requires_grad=True)
# P     = torch.rand(N, D, requires_grad=True)
# loss = graph_augmentation_loss(A_aug, P)
# loss.backward()

def node_generation_loss(X_ori: torch.Tensor, P: torch.Tensor) -> torch.Tensor:
    """
    Compute the node-generation loss:
        L_ag_node = || X_ori - X_ori @ P ||_{2,1}^2

    Where:
      ||M||_{2,1} = sum_i ||M[i]||_2  (sum of row L2 norms),
    and the squared outside denotes squaring that sum.

    Args:
      X_ori: Tensor of shape [N, F] — original node features
      P:     Tensor of shape [F, F] — projection matrix

    Returns:
      A scalar loss tensor.
    """
    # 1. Project and compute difference
    diff = X_ori - X_ori @ P        # shape [N, F]

    # 2. Compute row-wise L2 norms
    row_norms = diff.norm(p=2, dim=1)  # shape [N]

    # 3. Sum them to get the l2,1 norm
    l21 = row_norms.sum()              # scalar

    # 4. Square to obtain the final loss
    loss = l21 ** 2

    return loss

# Usage:
# X_ori = torch.randn(N, F)
# P     = torch.randn(F, F)
# loss  = node_generation_loss(X_ori, P)
# loss.backward()

def mask_features_by_q(X: torch.Tensor, P: torch.Tensor, zero_ratio: float = 0.2):
    """
    Mask features of X by a binary mask q derived from P.

    Args:
        X: Tensor of shape [N, F]
        P: Tensor of shape [N, F]
        zero_ratio: Fraction of smallest-sum features to zero out (default 0.2)

    Returns:
        X_aug: Masked feature tensor, same shape as X
        q: Binary mask of shape [F], 0 for masked features, 1 otherwise
    """
    # 1. Sum P over rows to get a length-F vector
    col_sums = P.sum(dim=0)  # shape [F]

    # 2. Identify indices of the smallest zero_ratio fraction
    F = col_sums.size(0)
    k = int(F * zero_ratio)
    if k > 0:
        _, idx = torch.topk(col_sums, k, largest=False)
    else:
        idx = torch.empty(0, dtype=torch.long)

    # 3. Build binary mask q
    q = torch.ones(F, device=P.device)
    q[idx] = 0

    # 4. Apply mask to each row of X (broadcast over N)
    X_aug = X * q.unsqueeze(0)

    return X_aug, q

# Example:
# X = torch.randn(1576, 1576)
# P = torch.randn(1576, 1576)
# X_aug, q = mask_features_by_q(X, P)

def contrastive_loss(z1, z2, tau=0.1):
    """
    Compute the contrastive loss
      L = -1/N * sum_i log( exp(sim(z1_i, z2_i)/tau)
                            / sum_j exp(sim(z1_i, z2_j)/tau) )
    where sim(a,b) = a·b / (||a|| * ||b||).

    Args:
        z1: Tensor of shape [N, D], first view embeddings
        z2: Tensor of shape [N, D], second view embeddings (positives aligned)
        tau: float, temperature parameter

    Returns:
        loss: scalar tensor
    """
    # 1. Normalize embeddings to unit vectors
    z1_norm = F.normalize(z1, dim=1)  # [N, D]
    z2_norm = F.normalize(z2, dim=1)  # [N, D]

    # 2. Compute similarity matrix: sim[i,j] = cos(z1_i, z2_j) / tau
    sim_matrix = torch.mm(z1_norm, z2_norm.t()) / tau  # [N, N]

    # 3. For each anchor i, the positive is sim_matrix[i,i], negatives are sim_matrix[i,j!=i]
    N = z1.size(0)
    positives = torch.diag(sim_matrix)               # [N]
    exp_sim = torch.exp(sim_matrix)                  # [N, N]
    exp_sum = exp_sim.sum(dim=1)                     # [N]

    # 4. Compute per-sample loss
    loss_i = -torch.log(torch.exp(positives) / exp_sum)  # [N]

    # 5. Return mean loss over the batch
    return loss_i.mean()

# —— Usage example ——
# N, D = 32, 128
# z1 = torch.randn(N, D)
# z2 = torch.randn(N, D)
# loss = contrastive_loss(z1, z2, tau=0.07)
# loss.backward()
